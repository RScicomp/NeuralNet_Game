{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGWF6ZCFWTmGjv5VM9jBUO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RScicomp/NeuralNet_Game/blob/master/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICBfCSy62mPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0942cf5f-f0ae-4216-d265-a739791f5d99"
      },
      "source": [
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "ENV_NAME = \"CartPole-v1\"\n",
        "\n",
        "GAMMA = 0.95\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "MEMORY_SIZE = 1000000\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "EXPLORATION_MAX = 1.0\n",
        "EXPLORATION_MIN = 0.0\n",
        "EXPLORATION_DECAY = 0.995\n",
        "\n",
        "\n",
        "class DQNSolver:\n",
        "\n",
        "    def __init__(self, observation_space, action_space):\n",
        "        self.exploration_rate = EXPLORATION_MAX\n",
        "\n",
        "        self.action_space = action_space\n",
        "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Dense(24, input_shape=(observation_space,), activation=\"relu\"))\n",
        "        self.model.add(Dense(24, activation=\"relu\"))\n",
        "        self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
        "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=LEARNING_RATE))\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        #self.memory.append((state, action, reward, next_state, done))\n",
        "        self.memory.append((gamenumber,state,action,reward,next_state,done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() < self.exploration_rate:\n",
        "            return random.randrange(self.action_space)\n",
        "        q_values = self.model.predict(state)\n",
        "        return np.argmax(q_values[0])\n",
        "    # fit on past data\n",
        "    def experience_replay(self):\n",
        "        if len(self.memory) < BATCH_SIZE:\n",
        "            return\n",
        "        #batch = random.sample(self.memory, BATCH_SIZE)\n",
        "        gamenumber = random(0,10)\n",
        "        self.memory(gamenumber)\n",
        "        cul_reward = 0\n",
        "        index=0\n",
        "        lastmove = len(batch)\n",
        "        for state, action, reward, state_next, terminal in batch:\n",
        "            q_update = reward\n",
        "            cul_reward+=reward\n",
        "            if not terminal:\n",
        "                #state1\n",
        "                #state2\n",
        "                #state3\n",
        "                #state4\n",
        "                #...\n",
        "                #gamma^2*np.amax(model.predict(state2)[0])\n",
        "                #gamma^3*np.amax(model.predict(state3)[0])\n",
        "                #amma^4*np.amax(model.predict(state4)[0])\n",
        "                #avg()\n",
        "                #If tilting to one direction, in future do it. PID\n",
        "                q_update = (reward + GAMMA * np.amax(self.model.predict(state_next)[0]))\n",
        "            q_values = self.model.predict(state)\n",
        "            #print(np.argmax(q_values[0]))\n",
        "            #update the q value for that action \n",
        "            q_values[0][action] = q_update\n",
        "            #Fitting during experience replay?\n",
        "            self.model.fit(state, q_values, verbose=0)\n",
        "            index+=1\n",
        "        decay = cul_reward/500\n",
        "\n",
        "        self.exploration_rate *= EXPLORATION_DECAY\n",
        "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
        "\n",
        "\n",
        "# env = gym.make(ENV_NAME)\n",
        "# observation_space = env.observation_space.shape[0]\n",
        "# action_space = env.action_space.n\n",
        "# dqn_solver = DQNSolver(observation_space, action_space)\n",
        "# run = 0\n",
        "# while True:\n",
        "#     run += 1\n",
        "#     state = env.reset()\n",
        "#     state = np.reshape(state, [1, observation_space])\n",
        "#     step = 0\n",
        "#     while True:\n",
        "#         step += 1\n",
        "#         #env.render()\n",
        "#         action = dqn_solver.act(state)\n",
        "#         state_next, reward, terminal, info = env.step(action)\n",
        "#         reward = reward if not terminal else -reward\n",
        "#         state_next = np.reshape(state_next, [1, observation_space])\n",
        "#         dqn_solver.remember(state, action, reward, state_next, terminal)\n",
        "#         state = state_next\n",
        "#         if terminal:\n",
        "#             print(\"Run: \" + str(run) + \", exploration: \" + str(dqn_solver.exploration_rate) + \", score: \" + str(step))\n",
        "#             break\n",
        "#         #TODO : CULMATIVE FIT RATHER THAN FIT EACH FRAME\n",
        "#         #1. Culmative fit rathar than fit each frame \n",
        "#         #2. Look Future States \n",
        "#         dqn_solver.experience_replay()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run: 1, exploration: 1.0, score: 12\n",
            "Run: 2, exploration: 0.985074875, score: 11\n",
            "Run: 3, exploration: 0.5535075230322891, score: 116\n",
            "Run: 4, exploration: 0.39166620452737816, score: 70\n",
            "Run: 5, exploration: 0.30028896908517405, score: 54\n",
            "Run: 6, exploration: 0.18099664897669618, score: 102\n",
            "Run: 7, exploration: 0.1572956799768517, score: 29\n",
            "Run: 8, exploration: 0.14663577052834775, score: 15\n",
            "Run: 9, exploration: 0.052741004581916356, score: 205\n",
            "Run: 10, exploration: 0.036033175291307735, score: 77\n",
            "Run: 11, exploration: 0.01964695745288379, score: 122\n",
            "Run: 12, exploration: 0.002619230772176422, score: 403\n",
            "Run: 13, exploration: 0.0003158739702481364, score: 423\n",
            "Run: 14, exploration: 9.580916531062733e-05, score: 239\n",
            "Run: 15, exploration: 9.221164398518892e-06, score: 468\n",
            "Run: 16, exploration: 1.9013243043905025e-06, score: 316\n",
            "Run: 17, exploration: 1.5587393237263896e-07, score: 500\n",
            "Run: 18, exploration: 8.498969331958042e-08, score: 122\n",
            "Run: 19, exploration: 6.967605514891022e-09, score: 500\n",
            "Run: 20, exploration: 7.376047899293826e-10, score: 449\n",
            "Run: 21, exploration: 6.047014645407561e-11, score: 500\n",
            "Run: 22, exploration: 6.211831675940932e-12, score: 455\n",
            "Run: 23, exploration: 4.1597395429238575e-12, score: 81\n",
            "Run: 24, exploration: 3.9563704193739394e-12, score: 11\n",
            "Run: 25, exploration: 1.1821141225801135e-12, score: 242\n",
            "Run: 26, exploration: 3.211148571573086e-13, score: 261\n",
            "Run: 27, exploration: 3.1690106903534777e-14, score: 463\n",
            "Run: 28, exploration: 2.5980110646861824e-15, score: 500\n",
            "Run: 29, exploration: 4.870235538374394e-16, score: 335\n",
            "Run: 30, exploration: 6.895272851999299e-17, score: 391\n",
            "Run: 31, exploration: 1.3320543369384077e-17, score: 329\n",
            "Run: 32, exploration: 1.9435018001217745e-18, score: 385\n",
            "Run: 33, exploration: 5.200620736871822e-19, score: 264\n",
            "Run: 34, exploration: 1.6585080864765254e-19, score: 229\n",
            "Run: 35, exploration: 1.3596742897250662e-20, score: 500\n",
            "Run: 36, exploration: 8.154345743544534e-21, score: 103\n",
            "Run: 37, exploration: 1.0496128683543439e-21, score: 410\n",
            "Run: 38, exploration: 9.138385395597335e-23, score: 488\n",
            "Run: 39, exploration: 7.491810123392246e-24, score: 500\n",
            "Run: 40, exploration: 6.141918566052529e-25, score: 500\n",
            "Run: 41, exploration: 5.035253570326732e-26, score: 500\n",
            "Run: 42, exploration: 2.6641127486434525e-26, score: 128\n",
            "Run: 43, exploration: 2.5338646239378005e-26, score: 11\n",
            "Run: 44, exploration: 2.3385825253694696e-26, score: 17\n",
            "Run: 45, exploration: 1.2687280776540307e-26, score: 123\n",
            "Run: 46, exploration: 7.128905157222706e-27, score: 116\n",
            "Run: 47, exploration: 3.605469435844926e-27, score: 137\n",
            "Run: 48, exploration: 2.95582767083317e-28, score: 500\n",
            "Run: 49, exploration: 2.4232398513220523e-29, score: 500\n",
            "Run: 50, exploration: 1.9866149285286723e-30, score: 500\n",
            "Run: 51, exploration: 6.9336298186686964e-31, score: 211\n",
            "Run: 52, exploration: 6.540812240401885e-32, score: 472\n",
            "Run: 53, exploration: 5.362273666140089e-33, score: 500\n",
            "Run: 54, exploration: 4.39608687938927e-34, score: 500\n",
            "Run: 55, exploration: 7.125979644555008e-35, score: 364\n",
            "Run: 56, exploration: 2.004859792366679e-35, score: 254\n",
            "Run: 57, exploration: 7.619712584130989e-36, score: 194\n",
            "Run: 58, exploration: 6.246775267612855e-37, score: 500\n",
            "Run: 59, exploration: 1.0176797012354612e-37, score: 363\n",
            "Run: 60, exploration: 8.343118349724923e-39, score: 500\n",
            "Run: 61, exploration: 3.031033349971881e-39, score: 203\n",
            "Run: 62, exploration: 2.4848947984398912e-40, score: 500\n",
            "Run: 63, exploration: 1.934024824620319e-40, score: 51\n",
            "Run: 64, exploration: 1.5855477891053987e-41, score: 500\n",
            "Run: 65, exploration: 6.899390719443993e-42, score: 167\n",
            "Run: 66, exploration: 2.8987029279107785e-42, score: 174\n",
            "Run: 67, exploration: 9.574245382101301e-43, score: 222\n",
            "Run: 68, exploration: 3.275245311162089e-43, score: 215\n",
            "Run: 69, exploration: 3.068625454813446e-43, score: 14\n",
            "Run: 70, exploration: 1.2262179231193765e-43, score: 184\n",
            "Run: 71, exploration: 1.166268288837538e-43, score: 11\n",
            "Run: 72, exploration: 1.1037033364325916e-43, score: 12\n",
            "Run: 73, exploration: 2.416828431678818e-44, score: 304\n",
            "Run: 74, exploration: 1.1861054112476094e-44, score: 143\n",
            "Run: 75, exploration: 3.957108611232033e-45, score: 220\n",
            "Run: 76, exploration: 1.6132787897533624e-45, score: 180\n",
            "Run: 77, exploration: 9.435807317094017e-46, score: 108\n",
            "Run: 78, exploration: 8.796343781995306e-46, score: 15\n",
            "Run: 79, exploration: 5.119115339596222e-46, score: 109\n",
            "Run: 80, exploration: 4.561690036697573e-46, score: 24\n",
            "Run: 81, exploration: 4.316976257918102e-46, score: 12\n",
            "Run: 82, exploration: 2.161547596996238e-46, score: 139\n",
            "Run: 83, exploration: 8.724537587966306e-47, score: 182\n",
            "Run: 84, exploration: 7.1525303643828e-48, score: 500\n",
            "Run: 85, exploration: 3.2073963415002624e-48, score: 161\n",
            "Run: 86, exploration: 1.5274555465786015e-48, score: 149\n",
            "Run: 87, exploration: 2.5515753980175447e-49, score: 358\n",
            "Run: 88, exploration: 1.0454825267831758e-49, score: 179\n",
            "Run: 89, exploration: 5.36767877644065e-50, score: 134\n",
            "Run: 90, exploration: 2.6742052782164476e-50, score: 140\n",
            "Run: 91, exploration: 1.755227943419328e-50, score: 85\n",
            "Run: 92, exploration: 5.826547460282276e-51, score: 221\n",
            "Run: 93, exploration: 3.9213415152224386e-51, score: 80\n",
            "Run: 94, exploration: 1.886272599656884e-51, score: 147\n",
            "Run: 95, exploration: 9.930218202372406e-52, score: 129\n",
            "Run: 96, exploration: 8.290671327144767e-52, score: 37\n",
            "Run: 97, exploration: 7.72881352133804e-52, score: 15\n",
            "Run: 98, exploration: 4.130455257553624e-52, score: 126\n",
            "Run: 99, exploration: 1.861520231779616e-52, score: 160\n",
            "Run: 100, exploration: 8.019463701024761e-53, score: 169\n",
            "Run: 101, exploration: 3.8191021646505847e-53, score: 149\n",
            "Run: 102, exploration: 1.1468342518538815e-53, score: 241\n",
            "Run: 103, exploration: 6.284494417461595e-54, score: 121\n",
            "Run: 104, exploration: 3.6573208791456565e-54, score: 109\n",
            "Run: 105, exploration: 2.117770364468768e-54, score: 110\n",
            "Run: 106, exploration: 1.0445596648353725e-54, score: 142\n",
            "Run: 107, exploration: 4.174044052132689e-55, score: 184\n",
            "Run: 108, exploration: 1.3855901657810995e-55, score: 221\n",
            "Run: 109, exploration: 2.0833359791070876e-56, score: 379\n",
            "Run: 110, exploration: 9.971309206872014e-57, score: 148\n",
            "Run: 111, exploration: 3.8471358774403356e-57, score: 191\n",
            "Run: 112, exploration: 2.0767128835704227e-57, score: 124\n",
            "Run: 113, exploration: 1.4188307552463221e-57, score: 77\n",
            "Run: 114, exploration: 2.2542455838846523e-58, score: 368\n",
            "Run: 115, exploration: 1.8632807444451582e-58, score: 39\n",
            "Run: 116, exploration: 2.945588057138448e-59, score: 369\n",
            "Run: 117, exploration: 1.5900505890165186e-59, score: 124\n",
            "Run: 118, exploration: 8.889724633444265e-60, score: 117\n",
            "Run: 119, exploration: 4.067137966296205e-60, score: 157\n",
            "Run: 120, exploration: 2.1091743568166209e-60, score: 132\n",
            "Run: 121, exploration: 8.38608654007991e-61, score: 185\n",
            "Run: 122, exploration: 6.875062203754582e-62, score: 500\n",
            "Run: 123, exploration: 2.6927295192341907e-62, score: 188\n",
            "Run: 124, exploration: 1.2257909437762564e-62, score: 158\n",
            "Run: 125, exploration: 5.254326481004503e-63, score: 170\n",
            "Run: 126, exploration: 2.552940434090355e-63, score: 145\n",
            "Run: 127, exploration: 6.464944578217506e-64, score: 275\n",
            "Run: 128, exploration: 2.9282730059189036e-64, score: 159\n",
            "Run: 129, exploration: 1.2119195051333984e-64, score: 177\n",
            "Run: 130, exploration: 3.2429780664063567e-65, score: 264\n",
            "Run: 131, exploration: 8.505631640448589e-66, score: 268\n",
            "Run: 132, exploration: 6.973067393333859e-67, score: 500\n",
            "Run: 133, exploration: 3.1112854833859994e-67, score: 162\n",
            "Run: 134, exploration: 1.5345966570592118e-67, score: 142\n",
            "Run: 135, exploration: 3.9056677115433996e-68, score: 274\n",
            "Run: 136, exploration: 1.226950222329875e-68, score: 232\n",
            "Run: 137, exploration: 4.570606685635007e-69, score: 198\n",
            "Run: 138, exploration: 2.8248123426263536e-69, score: 97\n",
            "Run: 139, exploration: 5.375629505207759e-70, score: 332\n",
            "Run: 140, exploration: 2.6781663723355636e-70, score: 140\n",
            "Run: 141, exploration: 1.5353221496798633e-70, score: 112\n",
            "Run: 142, exploration: 1.1537590428290825e-70, score: 58\n",
            "Run: 143, exploration: 7.024252452057264e-71, score: 100\n",
            "Run: 144, exploration: 4.006684585975072e-71, score: 113\n",
            "Run: 145, exploration: 7.325032030181763e-72, score: 340\n",
            "Run: 146, exploration: 3.631121930614106e-72, score: 141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f332d9aced7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", exploration: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexploration_rate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", score: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mdqn_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-f332d9aced7c>\u001b[0m in \u001b[0;36mexperience_replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m#update the q value for that action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mq_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexploration_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mEXPLORATION_DECAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexploration_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXPLORATION_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexploration_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}